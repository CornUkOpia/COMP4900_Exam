# COMP4900: Intro to Machine Learning
## The Language of Machine Learning
### Unsupervised
- Types of unsupervised machine learning include generative modeling, clustering, and anomaly detection.
#### Clustering
- Organizing data into clusters. Inferring distances between data points.
### Supervised
- Types of supervised machine learning include regression and classification.
#### Classification
- Predicts a finite categorical value belonging to a discrete set. (See Assignment 1, if the patient had hepatitis or didn't.)
#### Regression
- Predict a real continuous output value. Using the input features, predict the future result. 
### Input Variables
- Columns are called input variables or features or attributes.
### Output Variables
- Output variables / targets are the columns we are trying to predict. 
### Training example
- A row in the table is the training example / instance.
### Datasets
- The whole table containing all the training examples is the data set.
### Variable types
- Numerical: Real number measurements (Quantitative). 
- Categorical: From a discrete set (Qualitative)
- Ordinal: Categorical attributes that are ordered, allows ranking. (E.g: First, second, third)
### i.i.d assumption
- The independent and identically distributed assumption indicates that your data is independent and identically distributed. In supervised learning, the examples Xi in the training set are assumed to be independent and identically distributed.
- Independent: Every Xi is sampled according to some probability distribution D over the data domain X. For example, in an IQ study, if we measure an individual's IQ, it shouldn't provide any information about the next subject assessed. 
- Identically distributed: The distribution D is the same for all examples. One probability distribution should adequately model all values you observe in a sample. It is vital that the data is identically distributed as it indicates that you are are assessing a stable phenomenon. Example: If you are measuring the strength of a product and the mean strength increases as you collect more samples, it's hard to draw a conclusion. The mean strength depends on when you measure it. 
#### How to assess i.i.d in your dataset: 
- Independence: Consider how the data was collected for the data set. Was it randomly sampled or was it obtained in another way that would cause the information to be related to one another?
- Identical Distribution: Determine if there are any trends, graph the data in the order it was measured and look for patterns.
### Empiricial risk minimization
- Example for Explanation:
    - Problem: A simple supervised learning classification problem designed to classify spam emails. 
    - Each email has a label 0 (not spam) or 1 (spam). We denote the input variables with X and the output variable with Y.
    - The function f: X -> Y maps the input variables to the output variable.
    - Now that the problem has been defined, we need a model that is going to make our predictions. A synonym for model is the hypothesis H. The hypothesis is a function that takes input from X and produces an output label 0 or 1. This function h: X -> Y.
    - We want to find the hypothesis that minimizes our error, with this we come to the term empirical risk minimization. The term empirical implies that we minimize our error based on a sample set S from the domain set X.
    - Say we sample S from X, True error is based on the whole input X, however we only have access to S, a subset of X, we learn based on that sample of training examples. We don't have access to the true error, but to the empirical error.
    - The empirical error is also called generalisation error. In most problems, we don't have access to the whole X, instead S. We want to generalised based on S. This error is also called the risk. 
    - Since we have only S, it happens that we minimize the empirical error, but increase the true error. 
## Linear regression 
- The linear regression problem: : fw(xi) = w0 + ‚àëj=1:m Wj Xi,j where m is the number of features.
- The goal of linear regression is to find the best linear model given the training data. 
- Most common choice is to find the w that minimizes Err(w) (see Least Squares solution for this equation.)
### Least squares solution
- Find the best linear model given the data. 
- Most common choice is to find the w that minimizes squared error
    - Err(w) =  ‚àë i=1:n (Yi - w^T Xi)^2
    - Goal is to find a function in the form Fw(x) = w^T X
    - W is calculated such that the sum of squared error is minimized.
    - w = argmin ‚àë i=1:n (Yi - w^T Xi)^2
    - Yi (True target value)
    - w^T Xi (Predicted value for the target using the linear model and input variables.)
- Notation:
    - X is the n x m matrix of input data
    - Y is the n x 1 vector of output data
    - W is the m x 1 vector of weights
    - Fw(X) is the n x 1 vector of the predicted values
    - Err(w) is a scaler
    - In matrix notation
        - Fw(X) = X * w
        - Err(W) = (y - X * w)^T (y -  X * w)
    - wHat denotes the estimated weights that minimizes the error we defined.
    - ùúïErr(W)/ùúïw = -2X^T (y - X * w)
    - X^T (y - X * w) = 0
    - X^T * y - X^T * w = 0
    - wHat = (X^T * X)^-1 * (X^T * y)
    - Best Fitted model: yHat = X * wHat
### Predicting new data
    - To predict the outcome of new data Xnew -> Ynew
    - yHatNew = Xnew * wHat
### Gradient Descent
- Gradient descent is an iterative optimisation algorithm to find the minimum of a function.
- We want to produce a sequence of weight solutions w0,w1,w2,..., such that: Err(W0) > Err(W1) > Err(W2) > ...
- The algorithm: 
    - Given an initial weight vector w0,
    - Do for k = 0,1,2,...
        - calculate Z = ùúïErr(Wk)/ùúïWk
        - Wk+1 = Wk - Ak * Z (Take a step in the negative direction specified by the gradient)
    - End when || Wk+1 - Wk || < E
- Parameter Ak > 0 is the step size (or learning rate) for iteration k.
- Gradient descent steps down the function the direction of the steepest descent. The size of each step is determined the learning rater.
- In the gradient descent algorithm, one can infer that...
    - If the slope is positive, the value of the weights of the hypothesis decreases.
    - If the slope is negative, the value of the weights of the hypothesis increases.
- Failure in gradient descent. 
    - If Ak is too large, the gradient descent can overshoot the minimum and fail to converge or diverge.
    - If Ak is too small, the gradient descent will take small steps to reach the local minima and it will take a long time.
### Failure modes
#### Avoid Singularities
- The weights are not uniquely defined. Example: One feature is a linear function of the other. Solved by re-coding or dropping redundant columns of X.
- The number of features (m) exceeds the number of training examples (n). Solved by reducing the number of features using various techniques. 
### Bad fits
- Linear regression can be a bad fit in some cases.
- In order to improve the fit...
    - Pick a better function
    - Use more features
    - Get more data.
### Input variables for linear regression
- Original quantitative variables: X1,..., Xm
- Transformations of variables: e.g Xm+1 = log(Xi)
- Basis expansions: e.g. Xm+1 = Xi^2, Xm+2 = Xi^3
- Interaction terms: e.g. Xm+1 = XiXj
- In all cases, we can add Xm+1,...,Xm+k to the list of original variables and perform the linear regression.
### Order-nth fit
- Order-1 polynomial: Ex: y = 1.6x + 1.05
- Order-2 polynomial: Ex: y = 0.68x^2 + 1.74x + 0.73
- Constructing a curve that has the best fit to a series of data points, subject to constraints. The n value is the number of points to which the curve will be fitted. 
### Overfitting/Generalisation
- We can find a model that explains perfectly, the training data, but does not generalise well to new data.
#### Overfitting: 
- We can do really well in the training data, but it doesn't generalise to unseen data. We don't want to just minimize error on the training set. We want to minimize the true error and develop models that generalise well to unseen data. 
- Every model has a true error measured on all possible data items we could ever encounter, but we don't have all possible data. In order to decide what is a good model, we measure error over the training set. 
- Example: Suppose we compare 2 models F and G trained using the same algorithm, assume F has a lower error on the training set and G has lower true error, then our algorithm is overfitting.
#### Generalisation:
- In ML, our goal is to develop models that generalise.
- Overly simple model:
    - High training error and high test error.
- Overly complex model:
    - Low training error but high test error.
### Uses of data
- Paritioning the data into 3 sets help to evaluate the data.
#### Training set
- Used to fit a model (find the best hypothesis in the class; learn parameters)
#### Validation set
- Used for model selection, i.e., to estimate true error and compare hypothesis classes. (E.g., compare different order polynomials). 
- Validation set is used to compare different models during development.
    - Compare hypothesis/model classes. E.g., should I use a first- or second-order polynomial fit?
- Compare hyperparameters (i.e., a parameter that is not learned but that could impact performance). E.g., what learning rate should I use?
#### Test set
- What you report the final accuracy on.
### K-fold cross validation
- Instead of just one validation set, we can evaluate on many splits!
    - Consider k partitions of the training/non-test data (usually of equal size).
    - Train with k-1 subsets, validate on kth subset. Repeat k times.
    - Average the prediction error over the k rounds/folds.
### Cross validation for comparing models
- Say we have 2 models and this is a 5-fold cross validation
- Model/hypothesis A: Linear regression with basic features 
    - ErrA = 1/5 ‚àëj=1:5 Err^A_I (Average error of model A across all folds.)
- Model/hypothesis B: Linear regression with quadratic expansions of features
    - ErrB = 1/5 ‚àëj=1:5 Err^B_I (Average error of model B across all folds.)
- If ErrA < ErrB then we should use Model A, we should use a linear regression model with basic features.  
- Then to get the final Model A weights, we train on the entire dataset, ignoring the cross validation folds.
### Leave one out cross validation
- Let k = n, the size of the training set
- For each model / hyperparameter setting,
    - Repeat n times:
        - Set aside one instance (xi, yi) from the training set.
        - Use all other data points to find w (optimization).
        - Measure prediction error on the held-out (xi, yi).
    - Average the prediction error over all n subsets.
- Choose the setting with lowest estimated true prediction error.

## Linear Classification
### Classification Problems
- Y is a finite discrete set
- Given data set D = (Xi, Yi), with Yi, find a hypothesis which best fits the data.
    - If Yi = (0,1), this is a binary classification.
    - If Yi can take more than two values, the problems is called multi-class classifications.
### Classification via linear regression
- Example: A tumor classifier.
    - Input: X - Tumor size
    - Binary output:
        - Y = {No recurrence = 0; Recurrence = 1}
    - yHatn = Xn (X^T * X)^-1 * X^T * Y
    - How to get a binary output?
        - Threshold: If yHat > threshold then norecurrence class, if yHat <= then Recurrence class.
        - Interpret output as probability: yHat = Probability (Recurrence)
### Probabilistic 
- Estimate P(y | x), the conditional probability of the target variable given the feature data.
### Discriminative Learning
- Partition the feature space into different regions, and classify points based on the region where they lie.
## Logistic Regression
### Probabilistic view of discriminative learning
- Suppose we have 2 classes: y = (0,1)
- What is the probability of class y = 1 given input X?
- Logistic Function = 1/ 1+exp(-a)
- Log-odds ratio = ln ((P(y = 1 | x))/ P(y = 0 | x))
### Discriminative learning
- Model the boundary between the different classes.
- a = Log-odds ratio = W0 + W1X1 + ... WmXm
- The decision boundary is the set of points for which the linear model predicts zero. a = 0.
    - In fact, we model decision boundary with linear model.
    - a = 0 means Class 1 is equally likely as Class 2.
    - If a > 0, Class 1 is more likely than Class 2.
    - If a < 0, Class 2 is more likely  than Class 1.
    - pHat(y = 1 | x) = ùúï(w^T * X) = 1 / (1 + e^-W^T*X)
    - Logistic regression has a decision boundary that is linear in X.
### Learning the weights
- For y = (0,1), the likelihood function is
    - L(D) = P(y1,...,yn|x1,...,xn,w)
    - The likelihood of the data L(D) = Probability of correctly classifying training the data given the model parameters
        - If Yi = 1, = ùúï(W^T * Xi)
        - If Yi = 0, = 1 - ùúï(W^T * Xi)
### Maximizing likelihood
- Our goal is to maximize the likelihood, we want to find the parameters than give the highest likelihood.
- Likelihood: L(D) =  ‚àëi=1:n ùúï(W^T * Xi)^Yi (1 - ùúï(W^T * Xi))^ 1 - Yi
    - Problem: Taking products of lots of small numbers is numerically unstable, making this function hard to optimise.
- Log likelihood: L(D) = ln(L(D)) = ‚àëi=1:n Yi * ln(ùúï(w^T * Xi)) + (1 - Yi) * ln(1 - ùúï(w^T * Xi))
- The negative log-likelihood of the logistic function is known as the cross-entropy loss.
- cross-entropy(D) = - ‚àëi=1:n Yi * ln(ùúï(w^T * Xi)) + (1 - Yi) * ln(1 - ùúï(w^T * Xi))
    - Basic idea: It measures how many bits of information we would need to correct the errors made by our model. 
- In cross validation, look at error metrics on the validation set, not loss.
### Gradient Descent
- ùúïErr(W)/ùúïw = - ‚àëi=1:n Xi (Yi - ùúï(w^T * Xi))
    - Yi = True output.
    - ùúï(w^T * Xi) = Predicted output.
- Update rule: Wk+1 = Wk + aK * ‚àëi=1:n Xi (Yi - ùúï(w^T * Xi))
- Move in a direction that makes our prediction better.
- The algorithm:
- Given an initial weight vector w0,
- Do for k=0,1,2,...
    - Calculate T = ùúïErr(W)/ùúïw = - ‚àëi=1:n Xi (Yi - ùúï(w^T * Xi))
    - wK+1 = wK - aK * T (Take a step in the negative direction specified by the gradient.)
- End when ||wK+1 - wK|| < E
### Classification of a new observation
- After estimating w using gradient descent, calculate probabilities for a given new feature vector Xnew as follows:
    - p(yNew = 1 | xNew) = ùúï(w^T * xNew)
    - p(yNew = 0 | xNew) = 1 - ùúï(w^T * xNew)
- If p(yNew = 1 | xNew) > p(yNew = 0 | xNew) then yNew = 1 (xNew belongs to class 1)
- If p(yNew = 0 | xNew) > p(yNew = 1 | xNew) then yNew = 0 (xNew belongs to class 0)
### Generative learning
- Model the distribution of the different class.
- Separately model P(x|y) and P(y). Use Bayes' rule, to estimate P(y|x):
- P(y = 1|x) = (P(x|y = 1) * P(y = 1)) / P(x)
    - P(y = 1 | x) (The conditional probability of the target class (Our prediction))
    - P(x | y = 1) (How likely are we to see the observed features if the point was from class 1?)
        - Usually hard to estimate.
    - P(y = 1) (What is the marginal probability of this class? Ignoring the features, how likely are we to see class 1?)
    - P(x) (What is the marginal probability of the observed features? This is independent of the class.)
    - P(y) (Marginal probability of the class wihthot considering the features)
        - Usually easy to estimate.
- Example from spam classification: 
    - P(y = 1) = 0.01 -> In general, 1% of emails are spam.
    - P(x|y = 1) = 50% -> 50% chance of observed features occurring in a spam email.
    - P(x) = 0.10 -> 10% chance of seeing the observed features in a random email
    - P(y = 1|x) = 0.05 -> 5% chance of the email being spam.
- Why is P(x|y) and P(y) modeled seperately in Generative learning?
    - It gives extra flexibility. In the context of the spam email, suppose the spammers become more active with up to 20% of emails being spam. All that is needed to be done is modifying P(y).
    - Modeling P(x|y) allows us to make structural assumptions about the data generating process.
    - Generative models work well with smaller datasets.
### Linear Discriminant Analysis
- Linear Discriminant Analysis is a dimensionality reduction technique.     
    - LDA reduces the number of dimensions in a dataset while retaining as much information as possible. 
    - LDA uses the information from all features to create a new axis and projects the data on to the new axis in such a way as to minimizes the variance and maximizes the distance between the means of the two classes.
- LDA makes Gaussian assumptions about P(x|y)
- LDA is used for classification.
- The number of parameters to estimate in LDA is more than the number of parameters in Logistic Regression.
- LDA makes the assumptions that your data is Gaussian and that each attribute has the same variance. 
- Every class is assumed to be a Gaussian/normally distributed cluster of data points. 
- P(x|y=0) and P(x|y=1) are assumed to have the same covariance matrix. 
- LDA supports binary and multi-class classifications
#### Limations of Logistic Regression
- Two-Class Problems: Logistic regression is intended for two-classes or binary classification problems.
- Unstable with few examples / seperated classes.
### Higher-order features
- To get more flexible (non-linear) decision boundaries. Use higher-order features.
- X1,X2 are linear.
- X1,X2,X1X2,X1^2, X2^2 are curved and give a more flexible decision boundary.  
### Quadratic Discriminant Analysis
- LDA assumes all classes have the same covariance matrix.
- In QDA, each class uses its own estimate of variance or covariance where there are multiple input variables
- QDA allows different covariance matrices for each class k.
- QDA has more parameters to estimate, but greater flexibility to estimate the target function with a risk of overfitting. 
- QDA is more accurate than LDA. 
- LDA is faster than QDA due to the complex matrix operations and training time. 
- LDA is easier to analyse. 
### Scaling up Generative Learning
### Naive Bayes
### Assumptions
### Training
### Bernoulli
### Text classification
### Laplace Smoothing
### Evaluation, Bias-Variance, and Regularization
### Preprocessing raw data
### Multi-class classification
### Performance
### Terminology
### Common measures
### Receiver operating characteristics
### Area under curve
### Bias and variance in Machine learning
### Ridge Regression (L2-Regularisation)
### Lasso Regression (L1-Regularisation)
### Ridge vs. Lasso
### Decision Trees
### Linear assumptions
### Beyond linear models
### Decision Trees
### Example with Discrete Input
### Expressiveness
### Classification and regression
### How do we learn a decision tree?
### Choosing a good split attribute
### Quantifying Uncertainty
### Entropy
### Of a joint distributions
### Conditional
### Information gain
### Constructing decision trees
### Attribute selection
### Compare trees
### What makes a good tree?
### Avoiding overfitting
### Advantages
### Feature construction
### Steps to solving a supervised learning problem
### Encoding input into a feature vector
### Words
### TF-IDF
### N_grams
### Dimension Reduction:
### Feature extraction
### Feature selection
### Methods
### Wrapper and Filter
### Embedded
### Variable Ranking
### Principal Component Analysis
### Directions of largest variances.
### Scoring functions
### Nonlinear dependencies with MI
### Best-subset selection
### Instance Based Learning
### Nearest neighbour
### K-Nearest neighbour
### Limitations
### Distance-weighted NN
### Gaussian Weighting
### Ensemble Methods
### Bagging
### Boosting
### Stacking
### Weak Learners
### AdaBoost
### Meta-model
### Neural Networks
### Perceptron: A simple linear classifier
### Feed-forward neural networks
### Learning
### Generalising
### Fully connected networks
### Gradient descent 
### Preliminaries for NN
### Update for the output node
### Update for the hidden node
### Stochastic gradient descent
### Organizing training data
### Activation Functions
### Sigmoid
### Tanh
### ReLu
### Regularisation
### Compute gradients
### Overtraining
### Choosing the learning rate
### Adaptive optimization algorithms
### Convolutional Neural Networks
### NNs to CNNs
### Convolution as Dot Product
### Detecting virtual edges
### Zero padding
### Stride
### Convolution on RGB
### Two Filters
### Pooling
### Dropout Regularisation
### Softmax
### LeNet-5
### AlexNet
### VGG-16
### Recurrent Neural Networks
### Motivation
### Forward Pass
### Backpropagation
### Long-term dependencies
### Problem of long-term dependencies
### Long short-term memory (LSTM) units
### Bidirectional RNN
