# COMP4900: Intro to Machine Learning
## The Language of Machine Learning
### Unsupervised
- Types of unsupervised machine learning include generative modeling, clustering, and anomaly detection.
#### Clustering
- Organizing data into clusters. Inferring distances between data points.
### Supervised
- Types of supervised machine learning include regression and classification.
#### Classification
- Predicts a finite categorical value belonging to a discrete set. (See Assignment 1, if the patient had hepatitis or didn't.)
#### Regression
- Predict a real continuous output value. Using the input features, predict the future result. 
### Input Variables
- Columns are called input variables or features or attributes.
### Output Variables
- Output variables / targets are the columns we are trying to predict. 
### Training example
- A row in the table is the training example / instance.
### Datasets
- The whole table containing all the training examples is the data set.
### Variable types
- Numerical: Real number measurements (Quantitative). 
- Categorical: From a discrete set (Qualitative)
- Ordinal: Categorical attributes that are ordered, allows ranking. (E.g: First, second, third)
### i.i.d assumption
- The independent and identically distributed assumption indicates that your data is independent and identically distributed. In supervised learning, the examples Xi in the training set are assumed to be independent and identically distributed.
- Independent: Every Xi is sampled according to some probability distribution D over the data domain X. For example, in an IQ study, if we measure an individual's IQ, it shouldn't provide any information about the next subject assessed. 
- Identically distributed: The distribution D is the same for all examples. One probability distribution should adequately model all values you observe in a sample. It is vital that the data is identically distributed as it indicates that you are are assessing a stable phenomenon. Example: If you are measuring the strength of a product and the mean strength increases as you collect more samples, it's hard to draw a conclusion. The mean strength depends on when you measure it. 
#### How to assess i.i.d in your dataset: 
- Independence: Consider how the data was collected for the data set. Was it randomly sampled or was it obtained in another way that would cause the information to be related to one another?
- Identical Distribution: Determine if there are any trends, graph the data in the order it was measured and look for patterns.
### Empiricial risk minimization
- Example for Explanation:
    - Problem: A simple supervised learning classification problem designed to classify spam emails. 
    - Each email has a label 0 (not spam) or 1 (spam). We denote the input variables with X and the output variable with Y.
    - The function f: X -> Y maps the input variables to the output variable.
    - Now that the problem has been defined, we need a model that is going to make our predictions. A synonym for model is the hypothesis H. The hypothesis is a function that takes input from X and produces an output label 0 or 1. This function h: X -> Y.
    - We want to find the hypothesis that minimizes our error, with this we come to the term empirical risk minimization. The term empirical implies that we minimize our error based on a sample set S from the domain set X.
    - Say we sample S from X, True error is based on the whole input X, however we only have access to S, a subset of X, we learn based on that sample of training examples. We don't have access to the true error, but to the empirical error.
    - The empirical error is also called generalisation error. In most problems, we don't have access to the whole X, instead S. We want to generalised based on S. This error is also called the risk. 
    - Since we have only S, it happens that we minimize the empirical error, but increase the true error. 
## Linear regression 
- The linear regression problem: : fw(xi) = w0 + ‚àëj=1:m Wj Xi,j where m is the number of features.
- The goal of linear regression is to find the best linear model given the training data. 
- Most common choice is to find the w that minimizes Err(w) (see Least Squares solution for this equation.)
### Least squares solution
- Find the best linear model given the data. 
- Most common choice is to find the w that minimizes squared error
    - Err(w) =  ‚àë i=1:n (Yi - w^T Xi)^2
    - Goal is to find a function in the form Fw(x) = w^T X
    - W is calculated such that the sum of squared error is minimized.
    - w = argmin ‚àë i=1:n (Yi - w^T Xi)^2
    - Yi (True target value)
    - w^T Xi (Predicted value for the target using the linear model and input variables.)
- Notation:
    - X is the n x m matrix of input data
    - Y is the n x 1 vector of output data
    - W is the m x 1 vector of weights
    - Fw(X) is the n x 1 vector of the predicted values
    - Err(w) is a scaler
    - In matrix notation
        - Fw(X) = X * w
        - Err(W) = (y - X * w)^T (y -  X * w)
    - wHat denotes the estimated weights that minimizes the error we defined.
    - ùúïErr(W)/ùúïw = -2X^T (y - X * w)
    - X^T (y - X * w) = 0
    - X^T * y - X^T * w = 0
    - wHat = (X^T * X)^-1 * (X^T * y)
    - Best Fitted model: yHat = X * wHat
### Predicting new data
    - To predict the outcome of new data Xnew -> Ynew
    - yHatNew = Xnew * wHat
### Gradient Descent
- Gradient descent is an iterative optimisation algorithm to find the minimum of a function.
- We want to produce a sequence of weight solutions w0,w1,w2,..., such that: Err(W0) > Err(W1) > Err(W2) > ...
- The algorithm: 
    - Given an initial weight vector w0,
    - Do for k = 0,1,2,...
        - calculate Z = ùúïErr(Wk)/ùúïWk
        - Wk+1 = Wk - Ak * Z (Take a step in the negative direction specified by the gradient)
    - End when || Wk+1 - Wk || < E
- Parameter Ak > 0 is the step size (or learning rate) for iteration k.
- Gradient descent steps down the function the direction of the steepest descent. The size of each step is determined the learning rater.
- In the gradient descent algorithm, one can infer that...
    - If the slope is positive, the value of the weights of the hypothesis decreases.
    - If the slope is negative, the value of the weights of the hypothesis increases.
- Failure in gradient descent. 
    - If Ak is too large, the gradient descent can overshoot the minimum and fail to converge or diverge.
    - If Ak is too small, the gradient descent will take small steps to reach the local minima and it will take a long time.
### Failure modes
#### Avoid Singularities
- The weights are not uniquely defined. Example: One feature is a linear function of the other. Solved by re-coding or dropping redundant columns of X.
- The number of features (m) exceeds the number of training examples (n). Solved by reducing the number of features using various techniques. 
### Bad fits
- Linear regression can be a bad fit in some cases.
- In order to improve the fit...
    - Pick a better function
    - Use more features
    - Get more data.
### Input variables for linear regression
- Original quantitative variables: X1,..., Xm
- Transformations of variables: e.g Xm+1 = log(Xi)
- Basis expansions: e.g. Xm+1 = Xi^2, Xm+2 = Xi^3
- Interaction terms: e.g. Xm+1 = XiXj
- In all cases, we can add Xm+1,...,Xm+k to the list of original variables and perform the linear regression.
### Order-nth fit
- Order-1 polynomial: Ex: y = 1.6x + 1.05
- Order-2 polynomial: Ex: y = 0.68x^2 + 1.74x + 0.73
- Constructing a curve that has the best fit to a series of data points, subject to constraints. The n value is the number of points to which the curve will be fitted. 
### Overfitting/Generalisation
- We can find a model that explains perfectly, the training data, but does not generalise well to new data.
#### Overfitting: 
- We can do really well in the training data, but it doesn't generalise to unseen data. We don't want to just minimize error on the training set. We want to minimize the true error and develop models that generalise well to unseen data. 
- Every model has a true error measured on all possible data items we could ever encounter, but we don't have all possible data. In order to decide what is a good model, we measure error over the training set. 
- Example: Suppose we compare 2 models F and G trained using the same algorithm, assume F has a lower error on the training set and G has lower true error, then our algorithm is overfitting.
#### Generalisation:
- In ML, our goal is to develop models that generalise.
- Overly simple model:
    - High training error and high test error.
- Overly complex model:
    - Low training error but high test error.
### Uses of data
- Paritioning the data into 3 sets help to evaluate the data.
#### Training set
- Used to fit a model (find the best hypothesis in the class; learn parameters)
#### Validation set
- Used for model selection, i.e., to estimate true error and compare hypothesis classes. (E.g., compare different order polynomials). 
- Validation set is used to compare different models during development.
    - Compare hypothesis/model classes. E.g., should I use a first- or second-order polynomial fit?
- Compare hyperparameters (i.e., a parameter that is not learned but that could impact performance). E.g., what learning rate should I use?
#### Test set
- What you report the final accuracy on.
### K-fold cross validation
- Instead of just one validation set, we can evaluate on many splits!
    - Consider k partitions of the training/non-test data (usually of equal size).
    - Train with k-1 subsets, validate on kth subset. Repeat k times.
    - Average the prediction error over the k rounds/folds.
### Cross validation for comparing models
- Say we have 2 models and this is a 5-fold cross validation
- Model/hypothesis A: Linear regression with basic features 
    - ErrA = 1/5 ‚àëj=1:5 Err^A_I (Average error of model A across all folds.)
- Model/hypothesis B: Linear regression with quadratic expansions of features
    - ErrB = 1/5 ‚àëj=1:5 Err^B_I (Average error of model B across all folds.)
- If ErrA < ErrB then we should use Model A, we should use a linear regression model with basic features.  
- Then to get the final Model A weights, we train on the entire dataset, ignoring the cross validation folds.
### Leave one out cross validation
- Let k = n, the size of the training set
- For each model / hyperparameter setting,
    - Repeat n times:
        - Set aside one instance (xi, yi) from the training set.
        - Use all other data points to find w (optimization).
        - Measure prediction error on the held-out (xi, yi).
    - Average the prediction error over all n subsets.
- Choose the setting with lowest estimated true prediction error.

## Linear Classification
### Classification Problems
### Classification via linear regression
### High level views of binary classification
### Probabilistic 
### Discriminative Learning
### Probabilistic view of discriminative learning
### Discriminative learning logistic regression
### Learning the weights
### Maximizing likelihood
### Gradient Descent
### Classification of a new observation
### Generative learning
### Decision Boundaries
### Linear Discriminant Analysis
### Higher-order features
### Quadratic Discriminant Analysis
### Scaling up Generative Learning
### Naive Bayes
### Assumptions
### Training
### Bernoulli
### Text classification
### Laplace Smoothing
### Evaluation, Bias-Variance, and Regularization
### Preprocessing raw data
### Multi-class classification
### Performance
### Terminology
### Common measures
### Receiver operating characteristics
### Area under curve
### Bias and variance in Machine learning
### Ridge Regression (L2-Regularisation)
### Lasso Regression (L1-Regularisation)
### Ridge vs. Lasso
### Decision Trees
### Linear assumptions
### Beyond linear models
### Decision Trees
### Example with Discrete Input
### Expressiveness
### Classification and regression
### How do we learn a decision tree?
### Choosing a good split attribute
### Quantifying Uncertainty
### Entropy
### Of a joint distributions
### Conditional
### Information gain
### Constructing decision trees
### Attribute selection
### Compare trees
### What makes a good tree?
### Avoiding overfitting
### Advantages
### Feature construction
### Steps to solving a supervised learning problem
### Encoding input into a feature vector
### Words
### TF-IDF
### N_grams
### Dimension Reduction:
### Feature extraction
### Feature selection
### Methods
### Wrapper and Filter
### Embedded
### Variable Ranking
### Principal Component Analysis
### Directions of largest variances.
### Scoring functions
### Nonlinear dependencies with MI
### Best-subset selection
### Instance Based Learning
### Nearest neighbour
### K-Nearest neighbour
### Limitations
### Distance-weighted NN
### Gaussian Weighting
### Ensemble Methods
### Bagging
### Boosting
### Stacking
### Weak Learners
### AdaBoost
### Meta-model
### Neural Networks
### Perceptron: A simple linear classifier
### Feed-forward neural networks
### Learning
### Generalising
### Fully connected networks
### Gradient descent 
### Preliminaries for NN
### Update for the output node
### Update for the hidden node
### Stochastic gradient descent
### Organizing training data
### Activation Functions
### Sigmoid
### Tanh
### ReLu
### Regularisation
### Compute gradients
### Overtraining
### Choosing the learning rate
### Adaptive optimization algorithms
### Convolutional Neural Networks
### NNs to CNNs
### Convolution as Dot Product
### Detecting virtual edges
### Zero padding
### Stride
### Convolution on RGB
### Two Filters
### Pooling
### Dropout Regularisation
### Softmax
### LeNet-5
### AlexNet
### VGG-16
### Recurrent Neural Networks
### Motivation
### Forward Pass
### Backpropagation
### Long-term dependencies
### Problem of long-term dependencies
### Long short-term memory (LSTM) units
### Bidirectional RNN
